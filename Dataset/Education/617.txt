JISC HIKE Project – Huddersfield, Intota, KnowledgeBase+ Evaluation
Skip to content
JISC HIKE Project
Huddersfield, Intota, KnowledgeBase+ Evaluation
Menu and widgets
Latest Posts
Report on JUSP, KB+ and Intota Assessment
June 18, 2015
KB+ and JUSP
July 1, 2014
Reporting back!
October 15, 2013
On the road
October 3, 2013
HIKE Project report
October 3, 2013
Ideal Workflows
October 1, 2013
Analysis of the Journals workflow
March 19, 2013
JISC HIKE Project Workshop – 26th February
March 7, 2013
Meeting with Finance to discuss interoperability between Intota and Agresso
February 28, 2013
Library Management Systems and Interoperability with other University Systems – Financial
February 28, 2013
Recent CommentsDave Pattern on Ch-ch-ch-ch-changes!Liz Glenn on Ch-ch-ch-ch-changes!KB+ Community Advisory Group Meeting – 11th February 2013 « JISC HIKE Project on KB+ and the renewals processJournal Subscriptions and renewals « JISC HIKE Project on Core titlesONIX-PL, JISC Collections and 360 Resource Manager « JISC HIKE Project on KB+ Feedback – 3Meta
Log in
Entries RSS
Comments RSS
WordPress.org
Spam Blocked
12,816 spam blocked by Akismet
Report on JUSP, KB+ and Intota Assessment
Last year we blogged about an internal report we did on our assessment of JUSP, KB+ and Intota Assessment. At the time we shared the report with the 3 resources and have already seen a number of recommendations being adopted.
We thought that the report might be useful for other universities looking at how best to use the 3 resources in conjunction, our view is that with a little development all 3 are essential to our workflows 🙂
For more information, here is the Report
Posted on June 18, 2015Author Graham StoneCategories Intota, JUSP, KB+, News
KB+ and JUSP
Following the embedding of KB+ into the workflows of the Journals and E-Resources team at the end of the HIKE project, we recently decided to start looking at how we can incorporate JUSP into this workflow to help inform purchasing decisions and to evaluate and demonstrate the value of our collection.
With the expiry date of the NESLi2 deals (e.g. T&F SSH collection, Wiley STM collection, Sage Premier Collection) approaching we thought we would use these as case studies to investigate the information available within JUSP and KB+, how we could use it and if there was any information that we needed that was missing.
The first statistics that would be needed for this were the usage statistics for the collection. Using the Taylor and Francis SSH collection as an example, which provides us with access to all the titles predominantly from 1997 onwards, we do not receive access to the archive issues as part of this deal, we would require a report which gives us the usage statistics JR1-JR1a. This is available as a report in JUSP which provides you with the total figure for the publisher and with the figures for the individual titles. Additionally it provides you with the number of articles accessed by the publisher which were available as Open Access (OA). This statistic is valuable to know as it allows us to dismiss OA use from the JR1-JR1a figures to give us a more accurate cost per use.
However, there is one major limitation of this report. It does not provide you with a breakdown of the figures through the period chosen either by month or by year, instead it gives the cumulative total of the entire date range. Nevertheless this total is useful to know as it can be used with other figures to provide other evaluation measures such as the cost per download for the life of the package.
To obtain a breakdown of usage statistics by month you have to use the ‘JR1, JR1a and JR1 GOA’ report which provides a breakdown of your usage statistics by month and by title. One of the problems with this report is that it does not exclude the JR1a statistics, so the statistics include the downloads from the backfiles which are not part of the NESLi2 deals and therefore should not be included in the statistical analysis as it could skew the figures. However, having checked the current vs. archival usage (which is available on JUSP) the archive usage is minimal, as we don’t own the archive, so in this instance it would be possible to use this report. This will be more of a problem as we start to purchase publisher backfiles.
The report gives a monthly breakdown of the usage statistics by title over the time period and for the publisher requested. This information is really useful for a yearly review as it allows you to identify patterns of use and evaluate the value of a single title. It allows us to identify any low use core subscriptions which could potentially be cancelled.
A useful report from JUSP is the ‘View usage of titles and deals’ which retrieves the statistics for the packages by a publisher. This data for the entire package is needed once a year, and then at the end of the package lifetime to evaluate the use of the package and to help use decide whether this is the correct package to renew.
Although this report is very useful as it provides us with the Current JR1 total for all the titles within the package, and so excludes the backfile downloads, it only provides the headline figures for the titles for each year. Therefore it is not particularly useful for analysing the monthly use of the package over it’s lifetime. Many of the higher education institutions take NESLi2 packages, therefore these are the statistics that many people require, therefore would it be possible to provide a monthly breakdown of this report including the JR1, JR1a, JR1 GOA and Current JR1 for all the titles of the package?
It is also useful for us to know which of these titles are core titles. Not only does it allow us to identify any core titles that do not have high usage and could perhaps be considered for cancellation but it also allows us to identify any high use titles that we do not have as an individual title which we should consider purchasing at the end of the package lifetime as an individual subscription so that we do not lose access to the title. Although it is possible to identify your core titles in JUSP, we have tended to identify them in KB+ as this system has been developed to help us manage our NESLi2 packages and core titles. Having already identified our core titles in KB+ it is not time efficient to re-add the same information to JUSP – would it be possible for there to be more data sharing between the two systems and have this information transferred over?
Or, even better, would it be possible for JUSP and KB+ to be integrated? At the moment it is only possible to view the usage statistics of an individual journal within a package through KB+. Would it be possible to add links at package level to the different reports available in JUSP e.g. title usage of the package, top 20 titles and expand the number of reports available, a report showing the least used titles would be useful? At the moment it is crucial for us to be able to demonstrate value for money and to be able to identify the titles that are not being used so that we can promote them to allow us to get the most out of a package. If JUSP were integrated within KB+, JUSP could have a section which included the other reports, not package specific, that are available through JUSP.
Posted on July 1, 2014Author Amy DevenneyCategories KB+, Workflows
Reporting back!
After a busy month of disseminating our findings from the project at conferences and taking note of the ideas and feedback delegates had to offer, we thought it would useful to report back via the blog to stimulate further thoughts from you!
Briony and I presented at the National Acquisitions Group annual conference which was held at York on 4th and 5th September and at the Northern Collaboration conference on 13th September at the University of Huddersfield. In both sessions we started by presenting an overview of the project – the presentation for both these conferences can be found here.
We then split the delegates into groups and encouraged discussions around identifying pressure points in current workflows and considering how interoperability with other systems and co-operation with suppliers could create efficiencies. At the NAG conference we also had time for the groups to have a discussion about cultural change, we asked the delegates to think about the sorts of concerns staff might have concerning the implementation of a new library services platform, and to come up with different ways to manage these concerns.
Here are their thoughts:
Format GalleryPosted on October 15, 2013February 12, 2014Author Amy DevenneyCategories News
On the road
The HIKE project is on the road in autumn 2013.
On the road by macfred64 CC BY-NC
Check out our final report and the latest conference papers and workshops here.
Posted on October 3, 2013February 12, 2014Author Graham StoneCategories News
HIKE Project report
Earlier in the summer we launched the final project report
Devenney, Amy and Stone, Graham (2013) HIKE Report: to evaluate the suitability of Intota and KB+ for the UK higher education marketplace. Project Report
If you don’t have time to read the full report, there is also a handy executive summary for you to look at 🙂
Both are available at: http://eprints.hud.ac.uk/17976/
We would love to hear your views, so please leave a comment for us!
Posted on October 3, 2013February 12, 2014Author Graham StoneCategories News
Ideal Workflows
Following the end of the HIKE project Huddersfield committed to completely embedding KB+ in to the journals and e-resources processes, and to consider moving towards a library services platform as a replacement to the LMS. To achieve these aims it was recognised that a significant re-engineering of our workflows would need to take place. As a starting point we have attempted to produce a number of ideal workflows and identify the factors upon which these workflows would be dependent.
Selection of a new e-journal
The main alteration to current workflows would need to be around the journals and/or articles on reading lists. We would need academic staff to maintain accurate and up to date reading lists for their modules in order for Intota to run a report. Ideally this report would identify any journals which are on a reading list but are not currently held by the library. For this workflow to be successful it would also require the development of various API’s within Intota to allow interoperability with subscription agents, publishers and University financial systems.
Renewal of a journal
When analysing the current workflow for renewing a journal it became clear that the main area in which efficiencies could be made was at the data gathering stage and it was thought that the development of an API in Intota to pull this information from KB+ would be beneficial. This workflow would also benefit from development in the ordering and payment process through Intota and the University financial system.
Electronic PDA
This workflow almost completely automates the setting up of electronic PDA and requires very little input from the team. It also significantly reduces the amount of time required to set up electronic PDA as it removes the task of uploading and removing MARC records to the catalogue. If this workflow were to be realised the only input that would be needed from the institution would be a discussion and decision on which subject areas/class numbers to include in the PDA.
Reading Lists
Like the ideal workflow for the selection of a new e-journal this workflow is dependent on accurate reading lists being supplied in a timely manner and being maintained throughout the year by academics. We hope to be able to use a combination of in-house formulas and subject team expertise to govern the number of the books identified on reading lists that should be purchased. Student numbers on course modules would be provided by the student information system (SITS Vision) e.g.:
If an ebook is marked as essential reading buy 1 copy for every 25 students on the module but for a print copy buy 1 copy for every 10 students.
We believe that a significant proportion of the book budget will be spent through this acquisition method, therefore it is crucial that we get this right and consider all aspects of the workflow to identify and resolve any issues that may arise.
Selection by academics/librarians
After the reading list and PDA spend, the remaining book budget would come from selection. However this process could be significantly streamlined using Intota and web forms.
Posted on October 1, 2013February 12, 2014Author Amy DevenneyCategories News
Analysis of the Journals workflow
Analysis of the Journals workflow
Having analysed the workflows of the main processes of the Acquisitions team we felt it would be beneficial to carry out the same exercise for the E-Resources and Journals team. We decided to look at the workflow of the main processes in lifecycle of a journal – the selection of a new e-journal and the renewal of an e-journal. It is possible to identify a number of issues within these processes where efficiencies could be made and as such need to be considered by the developers of KB+ and a next generation library and web-scale management system.
Workflow to show the selection of an ejournal
Workflow to show a renewal of a journal subscription
MyReading software
As demonstrated in the workflow above, at the moment, the initial identification of a new journal title to be taken is by the Librarian requesting a new journal title to be ordered. However, with the development and implementation of MyReading project it is important that we consider how we will identify journal titles which academics have indicated contain relevant material for the students, which we currently do not subscribe to. At the moment, during the first year of the implementation of MyReading colleagues are going through the lists and checking them against our holdings manually. Not only is this time consuming but it also has a high risk of error. It was suggested that it may be possible to create an automated alert so that when a journal appears on a reading list, which we do not have access to, the team are alerted to look in to purchasing access.
Evaluation
Before subscribing to a journal, the team carry out an evaluation process on the proposed title. This data is then passed back to the Librarian and allows them to make an informed decision. The information that is collected by the team is outlined in the workflow above and includes the fourteen deal breakers outlined and recommended by the TERMS project as elements of the journal to be considered in best practice for the selection of e-resources (please see the TERMS wiki for more information http://library.hud.ac.uk/wikiterms/Main_Page).[1]
It is very time consuming collecting all this information from different places and it was suggested that the reporting feature on KB+ could be developed further to include more of the information that is used to evaluate the resource. Although the reporting feature currently looks at some of this information, such as licence criteria, it was wondered if this could be enlarged to include the criteria recommended as best practice by TERMS.
However, although these points are important for the institution to consider before entering into an agreement they are less of a concern if the resource has appeared on a reading list or the request is a result of specific research funding. In these case the new journal title request would by-passes much of the evaluation stage, although given the current monetary constraints on the journal budget it may mean that the ordering of a new title requires the cancellation of another – and for this to happen, some evaluation must take place.
Purchasing and Renewal
The team currently complete paper requisition forms which are passed to the Acquisitions Team to raise an order on Agresso. Once this order has been approved the order is placed with the subscription agent/publisher and they are given the purchase order number. Details of the order, such as the order number and price, are also entered onto a spreadsheet. The inputting of the information on paper requisitions, into Agresso and onto a spreadsheet ensures that work is duplicated and heightens the risk of error. Therefore we would ideally like a punch-out system from the Agresso eMarketplace to Swets, JISC Collections and other subscription agents and publishers. This would create efficiencies and reduce the risk of error. Any of the additional information that is recorded on the spreadsheet relating to the journal title could be recorded in the note field of the journal on KB+. This process could also be used to purchase the renewal subscriptions that occur every year.
Renewals
As laid out in the TERMS project best practice, the renewal process starts with an intelligence gathering stage.[2] Data, such as communications with vendors/publishers, periods of downtime and user feedback should be collected throughout the year and recorded in a consistent manner. KB+ and 360 Resource Manager offer the facility to be able to record this information in a consistent place and manner and it is encouraged that this is utilised. KB+ also offers the additional feature of a community forum which allows the librarians throughout the country to add and discuss issues with vendors, user feedback and downtime with other colleagues.
Other considerations are if the title is on a reading list and if the need for a specific journal title through specific research funding has ceased.
While a section of the renewals process has been greatly helped by the ‘renewals’ feature within KB+, which creates an easy to understand comparison spreadsheet, we feel that some information that is pertinent to the renewals process is missing from the comparison spreadsheet (see our previous blog post). In addition we need information on the % price increase, which won’t be available from KB+. We would like to investigate the possibility of creating these reports on Agresso, however, this would mean radically changing the workflow.
The final step in the renewals process, to check the access at the beginning of the subscription period, is currently done manually and is time intensive and open to error. An automated check of all the links alerting us to any links that are not working or current would be advantageous
Having studied the two main workflows for the E-Resources and Journals team it is clear that they are complex and time-consuming processes that require attention to detail. As such there is only so much automation can do to create efficiencies and therefore it is crucial that KB+ and a new next generation library and web-scale management systems such as Intota consider and develop the areas where efficiencies can be made.
[1] http://library.hud.ac.uk/wikiterms/Acquiring_New_Content
[2] http://library.hud.ac.uk/wikiterms/Ongoing_Evaluation_and_Access; http://library.hud.ac.uk/wikiterms/Annual_Review
Posted on March 19, 2013February 12, 2014Author Amy DevenneyCategories Journal subscriptions, KB+, Work package 5: Workflows, Workflows, Workpackage 4: APIs
JISC HIKE Project Workshop – 26th February
Dave Pattern opened the workshop with a welcome to all the participants over coffee before introducing Jane Burke from Serial Solutions. Jane presented an overview of Intota to the workshop, she began by discussing how recent changes in the format of the library’s collections, such as the move to a predominantly e-based collection, the subsequent revision of the acquisitions, the increased purchase of packages over individual titles, have meant that we are now using yesterday’s systems and tools to do today’s jobs. With the old LMS’s and their corresponding workflows designed around the acquisition, maintenance and discovery of print material the move towards e-resources means that they are increasingly not fit for purpose. Jane then moved on to give an update on the development of Intota announcing that they hope to have the Assessment module ready for customers in 2013 and the complete release of the full availability of Intota in 2014. She finished by giving a demonstration of the proposed workflow of acquiring a resource.
Damyanti Patel from JISC Collections then spoke to the workshop about KB+. She open with a discussion about the rationale behind KB+ and how it developed out of a recognition of the need for accurate data and subscription lists and a realisation that every Journals Librarian across the UK was duplicating work as they were all trying to maintain an accurate list. She then moved on to provide an update of the subscriptions that are currently on KB+, the team started by populating the site with Nesli2 collections but have quickly moved on to looking at non-Jisc and non-Nesli2 collections. Damyanti then finished by talking about the future of KB+, how they are hoping to add historical data to the site, work with international partners, improve integration with other systems such as ELCAT, JUSP and 360, and also expand KB+ to cover ebooks.
Damyanti has blogged about her day here: knowledgebaseplus.wordpress.com/2013/03/04/jisc-hike-project-workshop/
Dave Pattern and Graham Stone then presented an overview and update on the HIKE project – eprints.hud.ac.uk/16837/.
The afternoon session was focused around the discussion of three main areas: workflows, cultural change and API’s and interoperability. Having done a lot of work around these areas for Huddersfield we interested to see if other institutions were experiencing the same issues or if they were having different issues what these were so we could factor them into our evaluation.
Workflows
The intended outcome of this discussion was that the HIKE team would understand other institutions workflows, their pain areas where they felt efficiencies could be made and how the new systems of KB+ and Intota could help them.
Integration between the Library Management System, Reading List Software and Registry
This was raised by a number of different institutions as an area where they felt efficiencies could be made. At the moment many of the LMS’s have no integration with their reading list software, registry or book suppliers, therefore staff have to manually check the reading lists before placing an order with the supplier.
The University of Leicester reported basic integration between their LMS, reading list software (Talis Aspire) and book supplier (Coutts). Here academics create or edit their reading lists on Apsire, which creates a link between the reading list item and catalogue record as the list is being created using Z39.50. These lists are then reviewed by the Librarians who make the purchasing decisions, using a link on Talis Aspire the Librarians can link directly through to Coutts Oasis to place their order. Orders are then loaded overnight on to their LMS Sirsi-Dynix Symphony via EDI. Although this integration developed by Talis has helped reduced the amount of time spent checking the reading lists and inputting the book orders manually, staff are increasingly hoping for a completely automated process. It was agreed that ideally the reading lists created by the Academics with items marked either essential or suggested would, with the information about the number of students enrolled on the module from Registry, generate automatic orders based on a formula designed by the Librarians. The orders would not only go direct to the supplier but would also create an order record within the LMS so it would be possible to identify items that were on order.
During this discussion a few points were raised that must be considered when developing or implementing this integrated and automated process. Firstly this process would not take into account any cross-over between subjects such as English and History, or Maths and Physics were traditionally students have shared books. This could result in a large number of surplus books. Secondly this automated process of procurement would need to be considered when developing the integration between Intota and a financial system.
Other systems
Many of the delegates raised the lack of interoperability between the LMS and a wide variety of systems as a particular pain point. These included all of the above and also subscription agents, publishers and email. One major problem was the inability to record information – of course this is something that KB+ is offering.
The lack of interoperability has led some to by-pass the LMS completely.
Knowledge Base +
An issue raised regarding KB+ was that is was not yet embedded into current workflows – this could cause a problem even if libraries subscribed – if it is not part of the workflow it won’t get used. This is something for HIKE to consider when looking ‘dream workflow’.
A point was also raised regarding the amount of human intervention in the current workflows, and whether KB+ could offer rules to put into place to improve efficiencies and prevent human error.
Finance
Another area where it was agreed that duplication of work and the risk of error could be reduced was within the financial workflows. Like us the majority of the institutions duplicate all their financial accounting in the LMS and their institutions financial management system and have the same problems that we have outlined in earlier posts. It was agreed that interoperability between Intota and the financial system is highly sought after. Again a number of points were raised that would need to be considered when developing and implementing the integration between Intota and the financial system. These were how would the system deal with:
the top slicing of budgets which frequently occur in Libraries
the split responsibilities of different subject areas between different Librarians; and
the subscription to multi-year deals and the commitment of money through the years.
Acquisitions workflow
One of the issues raised when looking at the acquisitions workflows was that there was a marked difference between supplier databases and that there was an on-going out of print books problem.
It was also suggested that in the next national book contracts that technology needs to be a driver for choosing the contracts and that more attention needs to be paid to workflows, it was suggested that with Intota, EDI might be surplus to requirements!
Finally, nobody had a solution for the back office pain of dealing with the huge files involved with PDA.
Cultural Change
Throughout this project we have been aware that the implementation of either or both KB+ and Intota would lead to significant cultural change, and if the implementation of these systems were to be successful how this change is managed would be important. Therefore the theme of our second discussion was cultural change – we were interested in finding out what issues delegates thought their colleagues may have about the change and how these changes could be managed.
One of the main concerns people felt their colleagues would have was that the automation of many of the processes that make up their job would led to their de-skilling, loss of knowledge and less interesting jobs. Others thought that colleagues would be unsettled by the change in responsibilities and tasks as it may require additional training and the learning of new skills. Other factors that would contribute to colleagues feeling unsettled and anxious about such changes are the changes in routine, the lack of control and the feeling of incompetence.
After identifying the factors that could cause worry and apprehension regarding the implementation of these new systems we moved on to discuss how such a change could be managed to alleviate many of these concerns and for the system to be introduced successfully. Everyone agreed that the most important contribution to change management was to ensure that everyone was comfortable with the change and that staff at all levels have the relevant information, are fully involved and actively participating from the beginning.
It was felt that this could be enabled through a series of workshops which members of staff could come to and identify for themselves where there is duplication, a high risk of error and the points of pain in the old system and then help to define how the new system would bring benefits. It was felt that such a workshop would only work if an environment was created where staff would feel comfortable to come forward and express their concerns and anxieties about the new systems without being criticised or judged – staff need the opportunity to moan. One suggestion at this point was the use of an external moderator for such workshops? It was also suggested that these workshops should be continued after the implementation and evolve in to a user group were staff regularly evaluate the system and provides feedback to the company about possible developments. Staff need to understand the journey and help to identify the skills gaps.
It was suggested that we need to evolve people into new jobs. One way of offering reassurance to staff would be to show how the time that had become free through the automation of process would be used, it was suggested that this was not just giving staff mundane tasks but about giving them the opportunity to develop themselves through the participation in projects, etc. and to show how this would benefit the library. The timing of the installation of a new system was also believed to play an important part in how the change is perceived by staff. While implementation at the busiest period of the year was not recommended it was thought that it should be during a moderately busy period in order to demonstrate the effectiveness and benefits of the new system.
However, one group wondered to what extent have we already moved towards change anyway? At least two universities present have gone down the route of having a single team that swaps tasks, and others were thinking about doing the same thing. This was also linked back to the discussion on workflows – a possibility is that we could adopt one workflow for all resources – would this lead to one team, or would this spread things out too thinly? Do we still need experts in certain areas?
Another useful point was that many ‘back room’ teams have been dealing with change for some time – the biggest impact may actually be on the subject teams as their role may change, e.g. PDA vs. subject librarians orders. It was felt the these teams need to be engaged from the outset as there is a clear tension between the need to do more outreach work and ordering resources at granular level.
It was also pointed out that we live in a constantly changing and developing world and it is important that institutions and workflows have enough flexibility to be able to constantly enact change to keep in-line with these developments. Therefore it is important that using all the ideas above we can create an environment that is safe, comfortable and open to change. Intota is part of a suite of changes and it is our responsibility to adapt to them.
Finally it was argued that things take time and we have learnt many lessons already from our implementations of Summon. However, if we don’t make our processes more efficient it’s only a matter of time before somebody else does!
APIs
In the final session of the day, groups attempted to come up with lists of APIs and stuff they wish they had – or would want in a new system:
To talk to the financial system
Less duplication of effort – we are always trying to reconcile things
A wish list system
A way of reporting problems to all systems without having to re-write the same query three times
To be intelligent about students, e.g. on placement – linking student records to the student information system
An integrated VLE
Integration with every operating system in the University!
Active directory – smartcards etc.
Integrated with reading lists
RFID – Can we GPS track the orders
Notification of reservations
Could we give more information than just ‘on order’ or ‘reserved’  – e.g. use supply times from vendors to say when an item is expected?
Integrated ILL – not just with the British Library, but other local libraries too
Ethos!!!
Some thoughts on what we don’t want!
FTP
EDI
Imports and exports
Student records in the LMS – no duplication of data!
Single point of failure, e.g. staff who own important pieces of information
However, before we got too carried away, we also thought that removing the library catalogue completely might be a step to far for some – back to evolving our users/staff needs through cultural change.
With thanks to all who attended the HIKE workshop for their invaluable thoughts and feedback!
Posted on March 7, 2013Author Amy DevenneyCategories Intota, KB+, News, Work package 2: Integration, Work package 3: Implementation, Work package 5: Workflows, Work package 7: Dissemination, Workpackage 4: APIs
Meeting with Finance to discuss interoperability between Intota and Agresso
We recently met with some colleagues in the University Finance department to discuss the procurement process for books. We covered our current workflows, an ideal workflow and the possible interoperability between Intota and Agresso that would be needed to facilitate this.
We began by discussing the current workflows (which can be seen in the previous blog post ‘Analysis of ordering processes in the acquisitions team at Huddersfield’) and agreed that the areas we have highlighted as pressure points and that could be streamlined, were definitely areas that we needed to consider rationalising. We also looked at how our present workflow represented a “financial danger zone” to the University as it could lead to delays in the financial commitment for outstanding orders. Given the period of economic austerity we are in at the moment, and that Agresso is used for the budget monitoring of the whole University, it is crucial that Agresso has accurate and real-time information available at all times for the University’s Senior Management team for their constant strategic planning.
In light of this we moved on to discuss a possible workflow between Intota and the eMarketplace portal from Agresso in order to ensure reliable information.
It was proposed that Intota could be set up on eMarketplace as a supplier and that to order books we would log into Agresso, select eMarketplace as the procurement option and then punch out to Intota as a supplier. Once in Intota we could search for the resource we would like to buy using title, author, ISBN, etc. and this would then search all the different suppliers and return our results. We would then be able to select the items we would like to purchase and place them in a basket. After selecting all the items we would like to buy we could then return to Agresso and retrieve our ‘shopping’, pulling all the items we have placed in our basket back into Agresso. This would create a Purchase Order with each individual item having its own line. At this point it would be possible to select the correct Cost Centre and Nominal to charge the item to or split the price between different Nominals if needed.
We then raised the possibility of being able to split the book Nominal in Agresso down further to reflect the different subject’s budgets. Horizon (our current LMS) offers the opportunity for each subject to have its own fund code, and each year there can be up to thirty different fund codes. Our colleagues assured us that this would be possible in Agresso by using the categories within a Nominal. We would just need to inform them of the names of the different sub-sections of the nominal we would like them to set.
Once the ‘shopping’ has been pulled back into Agresso and assigned to the correct Cost Centre and Nominal this would be sent to the budget holder for approval. Once the whole order has been approved it is sent to the supplier/suppliers and the money is committed on Agresso. Upon receiving the books into the Acquisition’s department we would need to receive the items on Agresso, this would allow the electronic invoice that has been sent by the supplier to automatically be paid by either BAC’s or credit card depending on the preference of the institution. However, the payment method of the supplier would have to have been set up in advance, when the supplier was created, and for payment by credit card to be possible the supplier must have the facility to accept online payments. Agresso also has the functionality, providing the correct fields are known, to be able to send a file to update Intota and make the items received and available. This file could be programmed to update Intota at regular intervals, the frequency of which can be determined by the institution. It was noted that this workflow would not create an order record within Intota and that the item would only be recorded on Intota after it had been received in Agresso. Is this a problem? Would we need to know which books are on order? After a brief discussion we decided that is was something that we would need to discuss further, however it may be possibly be something for Intota to consider – the ability to create an order record from the ‘shopping basket’ which is exported to Agresso.
We then looked at RFID receiving, currently in practice at UCLAN, and questioned whether with the workflow above would still be possible if this was introduced. Our colleagues said that Agresso can currently read HTML and barcodes therefore it may be possible for it to read the information in an RFID tag to receive the item. However, it was stressed that the line number of the order would have to be programmed into the tag in order for Agresso to receive the item and reconcile the financial information.
Finally, we discussed reporting, budget management and planning options. It was agreed that if all the information in Agresso was accurate and in real time it would be possible for those who manage the budgets to continue using Agresso. However, it was pointed out that few Librarians use Agresso and that they may feel more comfortable accessing the information they need in Intota. The web version of Agresso offers a homepage which can display real time information relating to selected budgets either as figures or as graphs, therefore we wondered whether it would be possible for Intota the pull this information, via an API, to the dashboard of Intota. If the information was pulled each time the user logs on it would ensure the figures were accurate.
Recommendations
In order for Agresso to be able to pay the correct supplier after pulling the ‘shopping’ in from Intota via the eMarketplace, we would need the suppliers to have been set up in advance and for Intota to be able to provide unique identifiers for the different suppliers within Intota to be able to identify the suppliers of each item placed in the basket and for this information to be able to brought back in to Agresso to enable the correct supplier to be paid.
We currently charge the servicing costs and MARC records to different Nominals therefore we would need this pricing information to be available through Intota and to be able to be pulled back in to Agresso through eMarketplace in order for us to assign it to the correct Nominal.
Posted on February 28, 2013February 12, 2014Author Amy DevenneyCategories Intota, Work package 2: Integration, Work package 5: Workflows, Work package 7: Dissemination
Library Management Systems and Interoperability with other University Systems – Financial
Recent literature from the Information Management world demonstrates the increasing desire and need for the integration of Library Management Systems with other systems within a Higher Education Institution. Not only would such integration bring greater efficiency to workflows but it would also provide a better user experience for the student. For example, currently after paying a large fine, which has prohibited a student from borrowing resources their borrowing rights are not immediately nor automatically restored, instead the restoration of rights is reliant on an email between the Finance department and the library, a process which is open to error and delay. Despite this obvious and essential requirement for a next generation library and web-scale management system very little literature has focused on such integration and the benefits it would bring. The work that has appeared tends to focus on the elements of integration that provide an improved front end customer experience. For example, an article in the Spring 2010 issue of Panlibus looked at how the University of Plymouth has implemented ePayments in order to provide a better service to users. Rather than being restricted to payment at the Library counter during staffed hours, users can now view their accounts and pay any outstanding debts at any time and from anywhere.[1] For a similar reason the University of Wolverhampton also implemented ePayments.[2] While the need for integration between the two systems with the aim of efficiency and accuracy during the procurement process of resources has been recognised, very little research has been done. In 2009 Leeds Library and Information Service sought to link the electronic invoices in the library system to the financial system and Steve Kettle, Modernising Services Manager at Leicestershire Libraries, has outlined the inefficiencies with their payment process.[3]
Problems of existing systems and lack of integration
The main criticism of the lack of integration between the two systems is the necessity to manually key-in the data and receive items on both systems to ensure that both have a record of the lifecycle of the resource. Not only does this take time but it also increases the risk of error. Another concern about the absence of interoperability is that it results in the inability to report on spend and plan budgets accurately. Although the same data is input into both systems, mistakes whilst inputting the data could potentially mean the figures in the two systems do not match. If this was the case, which figure is the correct one? If there is a risk of inaccuracies and a doubling of the workload why do we use the two systems to account the same information? Why do we not focus on inputting the details into the one system?
Agresso is the financial system used at the University of Huddersfield, and by 135 other Higher Education Institutions, and is used by the financial department to oversee all transactions, save all relevant paperwork and prepare for any audits. With such a centralised system it would be impossible for us to move all our financial information for resources to the Library Management System. Horizon is also unable to support the recording of financial transactions to the level of detail that is required by the University auditors. Furthermore, Agresso is able to offer additional features, such as the ability to report on purchases broken down by supplier and period and the ability to split payments between nominal and cost centre, which are useful for financial analysis. However, despite the features offered by Agresso we still need to retain the financial information in Horizon because it offers the ability to be able to split the book budget to a more detailed level, such as subject fund codes, than is currently offered by Agresso. The resources are also ordered on Horizon through integration with the book suppliers database therefore if we were to move all the transactions to Agresso we would not have records of the complete lifecycle of the resource nor any information to use for any enquiries that may arise later.
Another issue that would need to be considered is the method of payment. At Huddersfield we currently pay for all our books by credit card and all the big electronic resource by BAC’s, therefore when looking at interoperability between the two systems it is important that they account and carry out an automated process for both payment methods.
Why such interoperability is needed?
Interoperability between the two systems, the LMS and HE financial system, is desirable as it would save duplication of effort, and it would provide more accurate figures for reporting, managing budget spend and planning budgets. The funding cuts in the UK HE have had a huge impact on staffing and resource budgets ensuring that staff time is at a premium and the usage of resources are closely monitored. Therefore the interoperability which would reduce the amount of staff time inputting data and would allow the resource budgets to be closely and accurately observed would be desirable.
What is currently available?
It appears as though the only product that is currently available that will facilitate the integration of an LMS with other systems is Capita Libraries Keystone. This software allows the sharing of data from the LMS with other systems within the University. For example, it can pass the invoice details from the LMS to the financial system or it could embed library account information in to VLE’s or portals. While Capita is definitely a step in the right direction there are still issues with the interoperability that it allows between the two systems. The movement of data between the two systems occurs overnight as a script is run to update the systems, this results in a delay between the receiving of an item and the actioning of the payment of the invoice.  Ideally we would like this to be near instantaneous so that our budgets are accurate and up to date. Additionally the integration between the LMS and financial system only works for book invoices as it is based on EDI invoices, so the integration is not possible for Journals or Standing Order invoices without introducing EDI invoicing which is not currently possible.
Therefore we are a long way from achieving complete interoperability between the two systems. We would ideally like to see Intota achieve this interoperability which would allow financial information to be passed between the two systems, for the updates to be done in real time and for overviews of the budgets to be available in Intota from the financial system for Librarians to be able to budget and plan accordingly.
With thanks to colleagues at University of Central Lancashire for their help with this post!
[1] Electonic payments Panlibus Spring 2010, p.20.
[2] Integration made easy Panlibus Spring 2009, p. 22.
[3] Integration made easy Panlibus Spring 2009, p. 22.
Posted on February 28, 2013February 12, 2014Author Amy DevenneyCategories News
Posts navigation
Page 1
Page 2
…
Page 4
Next page
Proudly powered by WordPress
